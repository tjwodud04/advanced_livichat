import base64
import asyncio
import threading
import json
import requests
import datetime
import random
import re
import time
from flask import jsonify, abort
from openai import AsyncOpenAI
from scripts.config import VERCEL_TOKEN, VERCEL_PROJ_ID, CHARACTER_SYSTEM_PROMPTS, CHARACTER_VOICE, EMOTION_LINKS, HISTORY_MAX_LEN
from scripts.utils import remove_empty_parentheses, markdown_to_html_links, extract_first_markdown_url, remove_emojis
from collections import deque
from dataclasses import dataclass, field
from typing import Deque, Dict, Any, List, Tuple, Literal

conversation_history = []
history_lock = threading.Lock()

# ---------------- ì¶”ê°€: ë§í¬ í›„ì²˜ë¦¬ ìœ í‹¸ ----------------

URL_RE = re.compile(r'(https?://[^\s<>"\']+)', re.IGNORECASE)
ANCHOR_RE = re.compile(r'<a\s+[^>]*href=["\']([^"\']+)["\'][^>]*>(.*?)</a>', re.IGNORECASE | re.DOTALL)

def _infer_reco_type(text: str) -> str:
    """í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œ ìœ í˜• ì¶”ì • (ìŒì•… ê´€ë ¨ í‚¤ì›Œë“œ ìˆìœ¼ë©´ music, ì•„ë‹ˆë©´ content)"""
    t = text.lower()
    music_kw = ["ìŒì•…", "ë…¸ë˜", "ê³¡", "ë®¤ì§", "playlist", "í”Œë ˆì´ë¦¬ìŠ¤íŠ¸", "song", "track"]
    return "music" if any(k in t for k in music_kw) else "content"

def _extract_links(raw: str) -> List[Tuple[str, str]]:
    """í…ìŠ¤íŠ¸ì—ì„œ ë§í¬ (href, label) ì¶”ì¶œ"""
    found: List[Tuple[str, str]] = []

    for m in ANCHOR_RE.finditer(raw):
        href, label = m.group(1).strip(), m.group(2).strip()
        if href and (href, label) not in found:
            found.append((href, label or href))

    for m in URL_RE.finditer(raw):
        url = m.group(1).strip()
        if not any(url == h for h, _ in found):
            found.append((url, url))
    return found

def _limit_links(ai_text: str) -> str:
    """ì¶”ì²œ ìœ í˜•ì— ë”°ë¼ ë§í¬ ê°œìˆ˜ë¥¼ ì œí•œ"""
    reco_type = _infer_reco_type(ai_text)
    links = _extract_links(ai_text)

    limit = 1 if reco_type == "music" else 2
    links = links[:limit]

    # ê¸°ì¡´ í…ìŠ¤íŠ¸ì—ì„œ ëª¨ë“  ë§í¬ ì œê±° í›„, ì œí•œëœ ë§í¬ë§Œ ë‹¤ì‹œ ë¶™ì´ê¸°
    cleaned = ANCHOR_RE.sub("", ai_text)
    cleaned = URL_RE.sub("", cleaned).strip()

    if links:
        link_htmls = [
            f'<a href="{href}" target="_blank">ğŸ”— {label}</a>'
            for href, label in links
        ]
        cleaned += "<br>" + " ".join(link_htmls)

    return cleaned

# ---------------- ê¸°ì¡´ í•¨ìˆ˜ ----------------

def get_openai_client(api_key: str):
    if not api_key:
        abort(401, description="OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    return AsyncOpenAI(api_key=api_key)

def upload_log_to_vercel_blob(blob_name: str, data: dict):
    if not VERCEL_TOKEN or not VERCEL_PROJ_ID:
        print("Vercel í™˜ê²½ë³€ìˆ˜(VERCEL_TOKEN, VERCEL_PROJECT_ID)ê°€ ì—†ì–´ ë¡œê·¸ë¥¼ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
    try:
        b64_data = base64.b64encode(json.dumps(data, ensure_ascii=False).encode()).decode()
        resp = requests.post(
            "https://api.vercel.com/v2/blob",
            headers={"Authorization": f"Bearer {VERCEL_TOKEN}"},
            json={"projectId": VERCEL_PROJ_ID, "data": b64_data, "name": blob_name}
        )
        resp.raise_for_status()
        print(f"ë¡œê·¸ ì €ì¥ ì„±ê³µ: {blob_name}")
    except Exception as e:
        print(f"Vercel Blob ë¡œê·¸ ì—…ë¡œë“œ ì˜ˆì™¸: {e}")

async def process_chat(request):
    try:
        if 'audio' not in request.files:
            return jsonify(error="ì˜¤ë””ì˜¤ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."), 400
        api_key = request.headers.get('X-API-KEY')
        character = request.form.get('character', 'kei')
        client = get_openai_client(api_key)

        # 1. Whisper STT
        audio_file = request.files['audio']
        stt_result = await client.audio.transcriptions.create(
            file=("audio.webm", audio_file.read()),
            model="whisper-1",
            response_format="text"
        )
        user_text = stt_result

        # 2. ê°ì • ë¶„ì„
        emotion_resp = await client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": 'ë‹¤ìŒ ë¬¸ì¥ì—ì„œ ë¶ˆêµì˜ ì¹ ì •(í¬,ë…¸,ì• ,ë‚™,ì• (ì‚¬ë‘),ì˜¤,ìš•)ì— ëŒ€í•´ JSON í˜•ì‹({"percent": {...}, "top_emotion": "ê°ì •"})ìœ¼ë¡œ ë¶„ì„í•´ì¤˜.'},
                {"role": "user", "content": user_text}
            ],
            temperature=0.0,
            max_tokens=200,
            response_format={"type": "json_object"}
        )
        emotion_data = json.loads(emotion_resp.choices[0].message.content)
        emotion_percent = emotion_data.get("percent", {})
        top_emotion = emotion_data.get("top_emotion", "í¬")

        # 3. ë©”ì¸ ë‹µë³€ ìƒì„±
        system_prompt = CHARACTER_SYSTEM_PROMPTS[character]
        with history_lock:
            messages = [{"role": "system", "content": system_prompt}] + conversation_history[-HISTORY_MAX_LEN:]

        needs_web_search = top_emotion in ["ë…¸", "ì• ", "ì˜¤"]
        ai_text = ""
        audio_b64 = ""
        youtube_link = None

        if needs_web_search:
            # (ìƒëµ) ê¸°ì¡´ LLM í˜¸ì¶œ ë° ai_text ìƒì„± ë¡œì§ ë™ì¼
            # ...
            ai_text = markdown_to_html_links(ai_text)
            # ë§í¬ í›„ë³´ ì°¾ê¸°
            youtube_link = extract_first_markdown_url(ai_text)
            # ë§í¬ í›„ì²˜ë¦¬
            ai_text = _limit_links(ai_text)

            # (ìƒëµ) TTS ì²˜ë¦¬ ë™ì¼
            # ...
        else:
            # (ìƒëµ) ê¸°ì¡´ LLM í˜¸ì¶œ ë° ai_text ìƒì„± ë¡œì§ ë™ì¼
            ai_text = remove_emojis(ai_text) or "ì•„ì§ ë‹µë³€ì„ ì¤€ë¹„í•˜ì§€ ëª»í–ˆì–´ìš”. ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?"
            ai_text = _limit_links(ai_text)  # í›„ì²˜ë¦¬ ì¶”ê°€
            # (ìƒëµ) TTS ì²˜ë¦¬ ë™ì¼
            # ...

        with history_lock:
            conversation_history.append({"role": "user", "content": user_text})
            conversation_history.append({"role": "assistant", "content": ai_text})
            if len(conversation_history) > HISTORY_MAX_LEN:
                conversation_history[:] = conversation_history[-HISTORY_MAX_LEN:]

        log_data = {
            "timestamp": datetime.datetime.now(datetime.timezone.utc).isoformat() + "Z",
            "character": character,
            "user_text": user_text,
            "emotion_percent": emotion_percent,
            "top_emotion": top_emotion,
            "ai_text": ai_text
        }
        now = datetime.datetime.now(datetime.timezone.utc)
        blob_name = f"logs/{now.strftime('%Y-%m-%dT%H-%M-%SZ')}_{character}.json"
        asyncio.create_task(asyncio.to_thread(upload_log_to_vercel_blob, blob_name, log_data))

        return jsonify({
            "user_text": user_text,
            "ai_text": remove_empty_parentheses(ai_text),
            "audio": audio_b64,
            "emotion_percent": emotion_percent,
            "top_emotion": top_emotion,
            "link": youtube_link
        })

    except Exception as e:
        import traceback; traceback.print_exc()
        return jsonify({"error": f"Failed to process request: {e}"}), 500 
